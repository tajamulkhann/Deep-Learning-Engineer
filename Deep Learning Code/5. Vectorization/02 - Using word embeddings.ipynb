{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using word embeddings\n",
    "\n",
    "Another popular and powerful way to associate a vector with a word is the use of dense _word vectors_, also called **word embeddings**. While the vectors obtained through one-hot encoding are binary, sparse (mostly made of zeros) and very high-dimensional (same dimensionality as the number of words in the vocabulary), _word embeddings_ are low-dimensional floating point vectors (i.e. _dense vectors_, as opposed to sparse vectors). Unlike word vectors obtained via one-hot encoding, **word embeddings are learned from data**. It is common to see word embeddings that are 256-dimensional, 512-dimensional, or 1024-dimensional when dealing with very large vocabularies. On the other hand, one-hot encoding words generally leads to vectors that are 20,000-dimensional or higher (capturing a vocabulary of 20,000 token in this case). So, **word embeddings pack more information into far fewer dimensions**.\n",
    "\n",
    "<img src=\"./resources/onehot-vs-embedding.png\" width=500>\n",
    "\n",
    "There are **two ways to obtain word embeddings**:\n",
    "\n",
    "- **Learn word embeddings jointly with the main task you care about** (e.g. document classification or sentiment prediction). In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network.\n",
    "- **Load into your model word embeddings that were pre-computed using a different machine learning task** than the one you are trying to solve. These are called _pre-trained word embeddings_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning word embeddings with the `Embedding` layer\n",
    "\n",
    "The simplest way to associate a dense vector to a word would be to **pick the vector at random**. The problem with this approach is that the resulting embedding space would have no structure: for instance, the words \"accurate\" and \"exact\" may end up with **completely different embeddings, even though they are interchangeable in most sentences**. **It would be very difficult for a deep neural network to make sense of such a noisy, unstructured embedding space.**\n",
    "\n",
    "To get a bit more abstract: **the geometric relationships between word vectors should reflect the semantic relationships between these words**. Word embeddings are meant to map human language into a geometric space. For instance, in a reasonable embedding space, we would expect synonyms to be embedded into similar word vectors, and in general we would expect the geometric distance (e.g. L2 distance) between any two word vectors to relate to the semantic distance of the associated words (words meaning very different things would be embedded to points far away from each other, while related words would be closer). Even beyond mere distance, we may want specific directions in the embedding space to be meaningful.\n",
    "\n",
    "\n",
    "In real-world word embedding spaces, **common examples of meaningful geometric transformations are \"_gender vectors_\" and \"_plural vector_\"**. For instance, by adding a \"female vector\" to the vector \"king\", one obtain the vector \"queen\". By adding a \"plural vector\", one obtain \"kings\". Word embedding spaces typically feature thousands of such interpretable and potentially useful vectors.\n",
    "\n",
    "**What makes a good word embedding space depends heavily on your task**: the perfect word embedding space for an English-language movie review sentiment analysis model may look very different from the perfect embedding space for an English-language legal document classification model, because **the importance of certain semantic relationships varies from task to task**.\n",
    "\n",
    "**It is thus reasonable to learn a new embedding space with every new task**. Thankfully, backpropagation makes this really easy, and Keras makes it even easier. It's just about learning the weights of a layer: the `Embedding` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# The Embedding layer takes at least two arguments:\n",
    "# 1) the number of possible tokens, here 1000 (1 + maximum word index),\n",
    "# 2) the dimensionality of the embeddings, here 64.\n",
    "embedding_layer = layers.Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer **takes as input a 2D tensor of integers**, of shape (`samples, sequence_length`), where each entry is a sequence of integers. It **returns a 3D floating-point tensor** of shape(`samples, sequence_length, embedding_dimensionality`).\n",
    "The Embedding layer is best understood as a **dictionary mapping integer indices (which stand for specific words) to dense vectors**. It takes as input integers, it looks up these integers into an internal dictionary, and it returns the associated vectors. It's effectively a dictionary lookup.\n",
    "\n",
    "When you instantiate an Embedding layer, its **weights (its internal dictionary of token vectors) are initially random**, just like with any other layer. **During training, these word vectors will be gradually adjusted via backpropagation**, structuring the space into something that the downstream model can exploit. Once fully trained, your embedding space will show a lot of structure -- a kind of structure specialized for the specific problem you were training your model for.\n",
    "\n",
    "Let's apply this idea to the IMDB movie review sentiment prediction, already seen in [this notebook](https://github.com/lucone83/deep-learning-with-python/blob/master/notebooks/chapter_03/01%20-%20Binary%20classifier.ipynb).\n",
    "We will restrict the movie reviews to the top 10,000 most common words, and cut the reviews after only 20 words. Our network will simply learn 8-dimensional embeddings for each of the 10,000 words, turn the input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the tensor to 2D, and train a single Dense layer on top for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "# Number of words to consider as features\n",
    "max_features = 10000\n",
    "\n",
    "# Cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 20\n",
    "\n",
    "# Load the data as lists of integers.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Turn our lists of integers into a 2D integer tensor of shape `(samples, maxlen)`\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 58us/sample - loss: 0.6570 - accuracy: 0.6513 - val_loss: 0.5949 - val_accuracy: 0.7076\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 42us/sample - loss: 0.5222 - accuracy: 0.7583 - val_loss: 0.5146 - val_accuracy: 0.7354\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 43us/sample - loss: 0.4537 - accuracy: 0.7897 - val_loss: 0.4951 - val_accuracy: 0.7504\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 41us/sample - loss: 0.4214 - accuracy: 0.8087 - val_loss: 0.4908 - val_accuracy: 0.7556\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 41us/sample - loss: 0.3990 - accuracy: 0.8202 - val_loss: 0.4912 - val_accuracy: 0.7636\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 41us/sample - loss: 0.3814 - accuracy: 0.8299 - val_loss: 0.4960 - val_accuracy: 0.7590\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 42us/sample - loss: 0.3658 - accuracy: 0.8375 - val_loss: 0.5024 - val_accuracy: 0.7568\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 42us/sample - loss: 0.3515 - accuracy: 0.8464 - val_loss: 0.5056 - val_accuracy: 0.7588\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 41us/sample - loss: 0.3368 - accuracy: 0.8541 - val_loss: 0.5129 - val_accuracy: 0.7544\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 51us/sample - loss: 0.3225 - accuracy: 0.8625 - val_loss: 0.5190 - val_accuracy: 0.7560\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# We specify the maximum input length to our Embedding layer so we can later flatten the embedded inputs\n",
    "model.add(layers.Embedding(10000, 8, input_length=maxlen))\n",
    "# After the Embedding layer, our activations have shape `(samples, maxlen, dimensionality(8))`.\n",
    "\n",
    "# We flatten the 3D tensor of embeddings into a 2D tensor of shape `(samples, maxlen * 8)`\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# We add the classifier on top\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get to a validation accuracy of `~76%`, **which is pretty good considering that we only look at the first 20 words in every review**. But note that **merely flattening the embedded sequences and training a single Dense layer on top leads to a model that treats each word in the input sequence separately**, without considering inter-word relationships and structure sentence (e.g. it would likely treat both \"this movie is shit\" and \"this movie is the shit\" as being negative \"reviews\"). **It would be much better to add recurrent layers or 1D convolutional layers on top of the embedded sequences** to learn features that take into account each sequence as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained word embeddings\n",
    "\n",
    "Instead of learning word embeddings jointly with the problem you want to solve, **it could be better to load embedding vectors from a pre-computed embedding space** known to be highly structured and to exhibit useful properties -- that captures generic aspects of language structure. \n",
    "The rationale behind using pre-trained word embeddings in natural language processing is very much the same as for using pre-trained convnets in image classification: **we don't have enough data available to learn truly powerful features on our own, but we expect the features that we need to be fairly generic**, i.e. common visual features or semantic features. In this case it makes sense to reuse features learned on a different problem.\n",
    "\n",
    "There are various pre-computed databases of word embeddings that can download and start using in a Keras `Embedding` layer. _Word2Vec_ is one of them. Another popular one is called _GloVe_, developed by Stanford researchers in 2014. It stands for \"Global Vectors for Word Representation\", and **it is an embedding technique based on factorizing a matrix of word co-occurrence statistics**. Its developers have made available pre-computed embeddings for millions of English tokens, obtained from _Wikipedia_ data or from _Common Crawl_ data.\n",
    "\n",
    "Let's take a look at how to get started using GloVe embeddings in a Keras model. The same method will of course be valid for Word2Vec embeddings or any other word embedding database. We will also use this example to refresh the text tokenization techniques: we will start from raw text, and work our way up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From raw text to word embeddings\n",
    "\n",
    "We will be using a model similar to the one we just went over -- embedding sentences in sequences of vectors, flattening them and training a Dense layer on top. But we will do it using pre-trained word embeddings, and instead of using the pre-tokenized IMDB data packaged in Keras, we will start from scratch, by downloading the original text data.\n",
    "\n",
    "- Head to http://ai.stanford.edu/~amaas/data/sentiment/ and download the raw IMDB dataset (if the URL isn't working anymore, just Google \"IMDB dataset\");\n",
    "- Uncompress it;\n",
    "- Collect the individual training reviews into a list of strings, one string per review, and also collect the review labels (positive / negative) into a labels list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = './datasets/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the data\n",
    "\n",
    "Let's vectorize the texts we collected, and prepare a training and validation split. We will merely be using the concepts we introduced earlier in this section.\n",
    "\n",
    "**Because pre-trained word embeddings are meant to be particularly useful on problems where little training data is available** (otherwise, task-specific embeddings are likely to outperform them), **we will add the following twist**: we **restrict the training data to its first 200 samples**. So we will be learning to classify movie reviews after looking at just 200 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88582 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100  # Cut reviews after 100 words\n",
    "training_samples = 200  # Train on 200 samples\n",
    "validation_samples = 10000  # Validate on 10000 samples\n",
    "max_words = 10000  # Consider only the top 10,000 words in the dataset\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f\"Found {len(word_index)} unique tokens.\")\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print(f\"Shape of data tensor: {data.shape}\")\n",
    "print(f\"Shape of label tensor: {labels.shape}\")\n",
    "\n",
    "# Split the data into a training set and a validation set.\n",
    "# But first, shuffle the data, since we started from data\n",
    "# where sample are ordered (all negative first, then all positive).\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the GloVe word embeddings\n",
    "\n",
    "- Head to https://nlp.stanford.edu/projects/glove/ (where you can learn more about the GloVe algorithm), and download the pre-computed embeddings from 2014 English Wikipedia. It's a 822MB zip file named glove.6B.zip, containing 100-dimensional embedding vectors for 400,000 words (or non-word tokens);\n",
    "- Un-zip it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the embeddings\n",
    "\n",
    "Let's parse the un-zipped file (it's a txt file) to build an index mapping words (as strings) to their vector representation (as number vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './embeddings/glove_6B/'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build an embedding matrix that we will be able to load into an `Embedding` layer. It must be a matrix of shape (`max_words, embedding_dim`), where each entry `i` contains the embedding_dim-dimensional vector for the word of index `i` in our reference word index (built during tokenization). Note that the index 0 is not supposed to stand for any word or token -- it's a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model\n",
    "\n",
    "We will be using the same model architecture as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GloVe embeddings in the model\n",
    "\n",
    "The `Embedding` layer has a single weight matrix: a 2D float matrix where each entry i is the word vector meant to be associated with index i. Simple enough. Let's just load the GloVe matrix we prepared into our Embedding layer, the first layer in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we freeze the embedding layer (we set its trainable attribute to `False`), following the same rationale used with in the context of pre-trained convnet features: when parts of a model are pre-trained (like our Embedding layer), and parts are randomly initialized (like our classifier), **the pre-trained parts should not be updated during training to avoid forgetting what they already know**. The large gradient update triggered by the randomly initialized layers would be very disruptive to the already learned features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 5ms/sample - loss: 0.6407 - acc: 0.6900 - val_loss: 0.7856 - val_acc: 0.5706\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 0.8934 - val_acc: 0.5627\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.8500 - val_acc: 0.5754\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.9518 - val_acc: 0.5668\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.5657\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.5654\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 1.0137 - val_acc: 0.5677\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.9039 - val_acc: 0.5741\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.9259 - val_acc: 0.5751\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0014 - acc: 1.0000 - val_loss: 1.1141 - val_acc: 0.5648\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "model.save_weights('./models/pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_performance_over_time(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_performance_over_time(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model **quickly starts overfitting**, unsurprisingly given the small number of training samples. Validation accuracy has high variance for the same reason, but seems to reach high 50s.\n",
    "\n",
    "Since we have so few training samples, performance is heavily dependent on which exact 200 samples we picked, and we picked them at random. If it worked really poorly for you, try picking a different random set of 200 samples, just for the sake of the exercise (in real life you don't get to pick your training data).\n",
    "\n",
    "We can also try to train the same model without loading the pre-trained word embeddings and without freezing the embedding layer. In that case, we would be learning a task-specific embedding of our input tokens, which is generally more powerful than pre-trained word embeddings when lots of data is available. However, in our case, we have only 200 training samples. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/sample - loss: 0.6920 - acc: 0.5350 - val_loss: 0.6922 - val_acc: 0.5119\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.4905 - acc: 0.9950 - val_loss: 0.6952 - val_acc: 0.5161\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.2691 - acc: 0.9950 - val_loss: 0.7078 - val_acc: 0.5135\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.1190 - acc: 1.0000 - val_loss: 0.7063 - val_acc: 0.5280\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0546 - acc: 1.0000 - val_loss: 0.7174 - val_acc: 0.5264\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.7197 - val_acc: 0.5275\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.5304\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.5311\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.5274\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.7468 - val_acc: 0.5330\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance_over_time(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy stalls in the low 50s. So in our case, pre-trained word embeddings does outperform jointly learned embeddings. If we increase the number of training samples, this will quickly stop being the case. Let's try it with an alternative model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 1s 730us/sample - loss: 0.6935 - acc: 0.5100 - val_loss: 0.6916 - val_acc: 0.5330\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 0s 190us/sample - loss: 0.4624 - acc: 0.9712 - val_loss: 0.7034 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 0s 191us/sample - loss: 0.1535 - acc: 0.9950 - val_loss: 0.6982 - val_acc: 0.5720\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 0.0345 - acc: 0.9975 - val_loss: 0.7059 - val_acc: 0.5830\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 0s 192us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7385 - val_acc: 0.6020\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.6020\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 0s 186us/sample - loss: 5.1629e-04 - acc: 1.0000 - val_loss: 0.7921 - val_acc: 0.5970\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 0s 184us/sample - loss: 1.2180e-04 - acc: 1.0000 - val_loss: 0.8318 - val_acc: 0.6060\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 0s 185us/sample - loss: 3.3191e-05 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 0.6120\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 0s 188us/sample - loss: 8.9387e-06 - acc: 1.0000 - val_loss: 0.9079 - val_acc: 0.6130\n"
     ]
    }
   ],
   "source": [
    "training_samples = 800 # Increase training set to 1000\n",
    "validation_samples = 1000\n",
    "\n",
    "alt_x_train = data[:training_samples]\n",
    "alt_y_train = labels[:training_samples]\n",
    "alt_x_val = data[training_samples: training_samples + validation_samples]\n",
    "alt_y_val = labels[training_samples: training_samples + validation_samples]\n",
    "\n",
    "\n",
    "alt_model = Sequential()\n",
    "alt_model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "alt_model.add(Flatten())\n",
    "alt_model.add(Dense(32, activation='relu'))\n",
    "alt_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "alt_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = alt_model.fit(alt_x_train, alt_y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(alt_x_val, alt_y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "Finally, let's evaluate the model with pre-trained embeddings on the test data. First, we will need to tokenize the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 31us/sample - loss: 1.1504 - acc: 0.5541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.150428861064911, 0.55412]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and evaluate the model\n",
    "model.load_weights('./models/pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an appalling test accuracy of 55%. Working with just a handful of training samples is hard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
